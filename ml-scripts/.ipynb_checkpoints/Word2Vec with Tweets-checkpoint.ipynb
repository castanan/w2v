{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import math\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from pyspark import SparkContext\n",
    "from pyspark import Row\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.ml.feature import Word2Vec\n",
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.mllib.linalg import Vectors\n",
    "from pyspark.ml.feature import PCA\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "import word2vecUtilities as wvu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Twitter Data as a Spark DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tweets read:  239082\n",
      "Elapsed time (seconds):  33.6140749454\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "datapath = '/Users/jorgecastanon/Documents/github/w2v/data/tweets.gz'\n",
    "tweets = sqlContext.read.json(datapath)\n",
    "tweets.registerTempTable(\"tweets\")\n",
    "twr = tweets.count()\n",
    "print \"Number of tweets read: \", twr \n",
    "# this line add ~7 seconds (from ~24.5 seconds to ~31.5 seconds)\n",
    "# Number of tweets read:  239082\n",
    "print \"Elapsed time (seconds): \", time.time() - t0\n",
    "#Elapsed time (seconds):  31.9646401405"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Keywords: christmas, santa, turkey, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>santa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>claus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>merry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>christmas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>eve</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0\n",
       "0      santa\n",
       "1      claus\n",
       "2      merry\n",
       "3  christmas\n",
       "4        eve"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filterPath = '/Users/jorgecastanon/Documents/github/w2v/data/filter.txt'\n",
    "filter = pd.read_csv(filterPath,header=None)\n",
    "filter.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Spark SQL to Filter Tweets:\n",
    "### + In english\n",
    "### + And containing at least one keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tweets after filtering:  15999\n",
      "Elapsed time (seconds):  10.3279871941\n",
      "Percetage of Tweets Used:  0.0669184631214\n"
     ]
    }
   ],
   "source": [
    "# Construct SQL Command\n",
    "t0 = time.time()\n",
    "sqlString = \"(\"\n",
    "for substr in filter[0]: #iteration on the list of words to filter (at most 50-100 words)\n",
    "    sqlString = sqlString+\"text LIKE '%\"+substr+\"%' OR \"\n",
    "    sqlString = sqlString+\"text LIKE '%\"+substr.upper()+\"%' OR \"\n",
    "sqlString=sqlString[:-4]+\")\"\n",
    "sqlFilterCommand = \"SELECT lang, text FROM tweets WHERE (lang = 'en') AND \"+sqlString\n",
    "\n",
    "# Query tweets in english that contain at least one of the keywords\n",
    "tweetsDF = sqlContext.sql(sqlFilterCommand).cache()\n",
    "twf = tweetsDF.count()\n",
    "print \"Number of tweets after filtering: \", twf \n",
    "# last line add ~9 seconds (from ~0.72 seconds to ~9.42 seconds)\n",
    "print \"Elapsed time (seconds): \", time.time() - t0\n",
    "\n",
    "print \"Percetage of Tweets Used: \", float(twf)/twr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse Tweets and Remove Stop Words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweetsRDD = tweetsDF.select('text').rdd\n",
    "\n",
    "def parseAndRemoveStopWords(text):\n",
    "    t = text[0].replace(\";\",\" \").replace(\":\",\" \").replace('\"',' ').replace('-',' ')\n",
    "    t = t.replace(',',' ').replace('.',' ')\n",
    "    t = t.lower().split(\" \")\n",
    "    stop = stopwords.words('english')\n",
    "    return [i for i in t if i not in stop]\n",
    "\n",
    "tw = tweetsRDD.map(parseAndRemoveStopWords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec: returns a dataframe with words and vectors\n",
    "\n",
    "+ Sometimes you need to run this block twice (strange reason that need to de-bug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time (seconds) to train Word2Vec:  8.02205491066\n"
     ]
    }
   ],
   "source": [
    "# map to df\n",
    "twDF = tw.map(lambda p: Row(text=p)).toDF()\n",
    "\n",
    "# default minCount = 5 (we may need to try something larger: 20-100 to reduce cost)\n",
    "# default vectorSize = 100 (we may want to keep default)\n",
    "t0 = time.time()\n",
    "word2Vec = Word2Vec(vectorSize=100, minCount=5, inputCol=\"text\", outputCol=\"result\")\n",
    "modelW2V = word2Vec.fit(twDF)\n",
    "wordVectorsDF = modelW2V.getVectors()\n",
    "print \"Elapsed time (seconds) to train Word2Vec: \", time.time() - t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5.1\n"
     ]
    }
   ],
   "source": [
    "print sc.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size:  3954\n"
     ]
    }
   ],
   "source": [
    "vocabSize = wordVectorsDF.count()\n",
    "print \"Vocabulary Size: \", vocabSize "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find top N closest words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>eve</td>\n",
       "      <td>0.913197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gift!</td>\n",
       "      <td>0.809615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eve!</td>\n",
       "      <td>0.757804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>üòçüòçüòç</td>\n",
       "      <td>0.750454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cup</td>\n",
       "      <td>0.749197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>indirect</td>\n",
       "      <td>0.734012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>christmas'</td>\n",
       "      <td>0.729327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>merry</td>\n",
       "      <td>0.728448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>tomorrow</td>\n",
       "      <td>0.718660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>wishing</td>\n",
       "      <td>0.703304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>life?</td>\n",
       "      <td>0.702444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>üéÑ</td>\n",
       "      <td>0.700686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>xmas</td>\n",
       "      <td>0.697368</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          word  similarity\n",
       "0          eve    0.913197\n",
       "1        gift!    0.809615\n",
       "2         eve!    0.757804\n",
       "3       üòçüòçüòç    0.750454\n",
       "4          cup    0.749197\n",
       "5     indirect    0.734012\n",
       "6   christmas'    0.729327\n",
       "7        merry    0.728448\n",
       "8     tomorrow    0.718660\n",
       "9      wishing    0.703304\n",
       "10       life?    0.702444\n",
       "11          üéÑ    0.700686\n",
       "12        xmas    0.697368"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topN = 13\n",
    "synonymsDF = modelW2V.findSynonyms('christmas', topN).toPandas()\n",
    "synonymsDF "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# As Expected, Unrelated terms are Not Accurate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>com</td>\n",
       "      <td>0.367090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bathroom</td>\n",
       "      <td>0.366653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>talks</td>\n",
       "      <td>0.365062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>too!</td>\n",
       "      <td>0.364378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>points</td>\n",
       "      <td>0.360151</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       word  similarity\n",
       "0       com    0.367090\n",
       "1  bathroom    0.366653\n",
       "2     talks    0.365062\n",
       "3      too!    0.364378\n",
       "4    points    0.360151"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synonymsDF = modelW2V.findSynonyms('dog', 5).toPandas()\n",
    "synonymsDF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA on Top of Word2Vec using DF (spark.ml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfW2V = wordVectorsDF.select('vector').withColumnRenamed('vector','features')\n",
    "\n",
    "numComponents = 3\n",
    "pca = PCA(k = numComponents, inputCol = 'features', outputCol = 'pcaFeatures')\n",
    "model = pca.fit(dfW2V)\n",
    "dfComp = model.transform(dfW2V).select(\"pcaFeatures\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3D Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jorgecastanon/anaconda/lib/python2.7/site-packages/matplotlib/collections.py:590: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  if self._edgecolors == str('face'):\n"
     ]
    }
   ],
   "source": [
    "word = 'christmas'\n",
    "nwords = 200\n",
    "\n",
    "#############\n",
    "\n",
    "r = wvu.topNwordsToPlot(dfComp,wordVectorsDF,word,nwords)\n",
    "\n",
    "############\n",
    "fs=20 #fontsize\n",
    "w = r['word']\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "height = 10\n",
    "width = 10\n",
    "fig.set_size_inches(width, height)\n",
    "\n",
    "ax.scatter(r['X'], r['Y'], r['Z'], color='red', s=100, marker='o', edgecolors='black')\n",
    "for i, txt in enumerate(w):\n",
    "    if(i<7):\n",
    "        ax.text(r['X'].ix[i],r['Y'].ix[i],r['Z'].ix[i], '%s' % (txt), size=20, zorder=1, color='k')\n",
    "ax.set_xlabel('1st. Component', fontsize=fs)\n",
    "ax.set_ylabel('2nd. Component', fontsize=fs)\n",
    "ax.set_zlabel('3rd. Component', fontsize=fs)\n",
    "ax.set_title('Visualization of Word2Vec via PCA', fontsize=fs)\n",
    "ax.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-means on top of Word2Vec using DF (spark.ml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Clusters (K) Used:  44\n",
      "Elapsed time (seconds) : 1.38142800331\n"
     ]
    }
   ],
   "source": [
    "t0=time.time()\n",
    "\n",
    "K = int(math.floor(math.sqrt(float(vocabSize)/2)))\n",
    "         # K ~ sqrt(n/2) this is a rule of thumb for choosing K,\n",
    "         # where n is the number of words in the model\n",
    "         # feel free to choose K with a fancier algorithm\n",
    "         \n",
    "dfW2V = wordVectorsDF.select('vector').withColumnRenamed('vector','features')\n",
    "kmeans = KMeans(k=K, seed=1)\n",
    "modelK = kmeans.fit(dfW2V)\n",
    "labelsDF = modelK.transform(dfW2V).select('prediction').withColumnRenamed('prediction','labels')\n",
    "\n",
    "print \"Number of Clusters (K) Used: \", K\n",
    "print \"Elapsed time (seconds) :\", time.time() - t0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
